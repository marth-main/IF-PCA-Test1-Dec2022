{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98715788",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ea051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edcf05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/aks13/Dropbox (Partners HealthCare)/ML stuff/NSLT_CT_IMG_samp/'\n",
    "directory = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ae200",
   "metadata": {},
   "source": [
    "#### Image resizing and moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize all images in the folder to standard size of 500 x 500\n",
    "# new images have '_renamed' at the end of the og filename\n",
    "\n",
    "def resize_img():\n",
    "    for item in directory:\n",
    "        if os.path.isfile(path+item):\n",
    "            im = Image.open(path+item)\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            imResize = im.resize((500, 500), Image.ANTIALIAS) #this smooths the image edges, maybe dont do? not sure\n",
    "            imResize.save(f + '_resized.png', 'PNG', quality = 90) #95 is recommended max, 75 is avg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ONLY RUN THIS WHEN YOU NEED TO RANDOMIZE A NEW FOLDER\n",
    "resize_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfda19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the resized images to a new folder\n",
    "# NSLT_CT_IMG_samp_resize\n",
    "import shutil\n",
    "\n",
    "for file in glob.glob('C:/Users/aks13/Dropbox (Partners HealthCare)/ML stuff/NSLT_CT_IMG_samp/*resized.png'):\n",
    "    shutil.move(file, 'C:/Users/aks13/Dropbox (Partners HealthCare)/ML stuff/NSLT_CT_IMG_samp_resize/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8078414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new directory of resized images --> /NSLT_CT_IMG_samp_resize/\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new path\n",
    "path = 'C:/Users/aks13/Dropbox (Partners HealthCare)/ML stuff/NSLT_CT_IMG_samp_resize/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476392bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab filenames and put into a list\n",
    "\n",
    "def get_imlist(path):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d787bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = get_imlist(path)\n",
    "filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3943787",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths_2 = [item.split('/') for item in filepaths]\n",
    "filepaths_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17799017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only the filename\n",
    "filepaths_3 = [item.pop() for item in filepaths_2]\n",
    "filepaths_3\n",
    "\n",
    "# rename\n",
    "filenames_imgs = filepaths_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab648d3",
   "metadata": {},
   "source": [
    "#### Converting resized images into arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27988253",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "# make empty array --> 500x500 size\n",
    "np_imgs = np.zeros((500, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757c08f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert each image into an array\n",
    "count = 0\n",
    "\n",
    "for f in glob.iglob('C:/Users/aks13/Dropbox (Partners HealthCare)/ML stuff/NSLT_CT_IMG_samp_resize/*.png'):\n",
    "    images = Image.open(f).convert('L') #convert to b/w THEN flatten, L is grayscale\n",
    "    images = np.asarray(images) # create the arrays...\n",
    "    images = [item.flatten() for item in images] #...then flatten before adding\n",
    "    np_imgs[count,:] #flattened image vector\n",
    "    count = count + 1\n",
    "    \n",
    "images = np.array(images)\n",
    "\n",
    "# add back filenames to this and make a new list\n",
    "# 1:1 ratio filename:array once flattened to 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a6d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a19430",
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames_imgs)\n",
    "# these two lists have to match in length or they wont combine correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b3f04",
   "metadata": {},
   "source": [
    "#### Convert arrays into a dataframe, matching filenames as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb081ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try --> just have the df from the flat_imgs arrays first\n",
    "# then insert the filenames as the first column\n",
    "\n",
    "df_v1 = pd.DataFrame(images, index=filenames_imgs)\n",
    "#df_v1 = pd.DataFrame(images[0:10], index=filenames_imgs[0:10]) #test 10 output\n",
    "\n",
    "df_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92378385",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06bfd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#from sklearn.preprocessing import StandardScaler #dont scale outliers lol\n",
    "\n",
    "X = df_v1.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f136d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5096f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old scaled method\n",
    "# trying without\n",
    "\n",
    "# scale the data\n",
    "##scaler = StandardScaler()\n",
    "##scaler.fit(X)\n",
    "##X_scaled = scaler.transform(X)\n",
    "##X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_v1 = PCA(n_components=5, random_state=42)\n",
    "pca_v1.fit(X)\n",
    "#pca_v1.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a07253",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_v1 = pca_v1.transform(X)\n",
    "#X_pca_v1 = pca_v1.transform(X_scaled)\n",
    "X_pca_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X #original df from pca arrays\n",
    "df_v1 # before doing anything\n",
    "X_pca_v1 #array of PCA values that were fit/transformed --> use this in IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccd6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d28375",
   "metadata": {},
   "source": [
    "#### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "# put the PCA array back to a DF to preserve the new components\n",
    "\n",
    "pca_v1_df = pd.DataFrame(X_pca_v1, index=filenames_imgs)\n",
    "pca_v1_df.columns = ['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4', 'PCA 5']\n",
    "pca_v1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388aff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_pca = ['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4', 'PCA 5']\n",
    "\n",
    "if_model = IsolationForest(max_samples=100, contamination=0.1, random_state=42)\n",
    "if_model.fit(pca_v1_df[anomaly_pca]) # use the PCA'd df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_v1_df['anomaly score'] = if_model.decision_function(pca_v1_df[anomaly_pca])\n",
    "pca_v1_df['anomaly'] = if_model.predict(pca_v1_df[anomaly_pca])\n",
    "pca_v1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71735ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_v1_df # -1 = outlier (anomaly), 1 = non-outlier (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca_v1_df.to_csv('nonscaled-check3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-CIRC-WS2]",
   "language": "python",
   "name": "conda-env-ML-CIRC-WS2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
